{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengambilan Data Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"1453638487106748422-1nZ6kd8UHSdpMhbRVBDb5TZlgZzLGg\"\n",
    "access_token_secret = \"Zg2kSmQHORGVu7j2priaAeu0R8VYNbWoLo9nq6Vjq8rdp\"\n",
    "api_key = \"RQ2hQDH5d4uilly17NReVlQjs\"\n",
    "api_key_secret = \"VS0KGnnvRwpIkzQOLCfjIPshvwq91g1yJOMSohSldXBY0rLy4t\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "api = tweepy.API(auth)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "search_key = \"telkomsel\"\n",
    "maxTweets = 2000\n",
    "tweetsPerQry = 10\n",
    "\n",
    "csvFile = open(\"hasil_20April.csv\",\"a+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=search_key, lang=\"id\").items(maxTweets):\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])\n",
    "csvFile.close()\n",
    "\n",
    "print(\"Download beberapa tweet\".format(maxTweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import numpy as int64\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import nltk\n",
    "import emoji, re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-20 15:27:28+00:00</td>\n",
       "      <td>b'@scorpeeoss aku pk Telkomsel 25-29k perbulan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-20 15:25:44+00:00</td>\n",
       "      <td>b'@yunointherain Oke Kak. Gyan cek dulu DM nya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-20 15:25:43+00:00</td>\n",
       "      <td>b'@Telkomsel udah min cek dmnya yaa';;;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-20 15:23:59+00:00</td>\n",
       "      <td>b'@iskameraa Oke Kak. Gyan cek dulu DM nya ya....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-20 15:23:58+00:00</td>\n",
       "      <td>b'@Telkomsel sudah ada di dm kakak :)';;;;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tanggal  \\\n",
       "0  2022-04-20 15:27:28+00:00   \n",
       "1  2022-04-20 15:25:44+00:00   \n",
       "2  2022-04-20 15:25:43+00:00   \n",
       "3  2022-04-20 15:23:59+00:00   \n",
       "4  2022-04-20 15:23:58+00:00   \n",
       "\n",
       "                                               tweet  \n",
       "0  b'@scorpeeoss aku pk Telkomsel 25-29k perbulan...  \n",
       "1  b'@yunointherain Oke Kak. Gyan cek dulu DM nya...  \n",
       "2           b'@Telkomsel udah min cek dmnya yaa';;;;  \n",
       "3  b'@iskameraa Oke Kak. Gyan cek dulu DM nya ya....  \n",
       "4         b'@Telkomsel sudah ada di dm kakak :)';;;;  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"hasil_20April.csv\", names=['tanggal','tweet']).dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_usernames_links(text):\n",
    "    text = re.sub(r'https\\:.*$', \":\", text)\n",
    "    return text\n",
    "data['tweet'] = data['tweet'].apply(remove_usernames_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_remove(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "def regex_remove(text):\n",
    "    reg = \"b'\"\n",
    "    return re.sub(reg, \" \", text)\n",
    "\n",
    "def url_remove(text):\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "    return text\n",
    "\n",
    "def remove_regex(text):\n",
    "    reg = \"RT\" \n",
    "    return re.sub(reg, \" \", text)\n",
    "\n",
    "def punc_remove(text):\n",
    "    pattern = \"[^\\b'\\@\\w]\"\n",
    "    return re.sub(pattern, \" \", text)\n",
    "\n",
    "def white_space(text):\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "cleaned = []\n",
    "\n",
    "def clean_text(text):\n",
    "    for i in text:\n",
    "        cleaned.append(number_remove(regex_remove(url_remove(remove_regex(punc_remove(white_space(re.sub(\"[\\n\\r\\t\\xa0]\",\" \",i).strip())))))))\n",
    "clean_text(data[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-20 15:27:28+00:00</td>\n",
       "      <td>b'@scorpeeoss aku pk Telkomsel 25-29k perbulan...</td>\n",
       "      <td>aku pk Telkomsel  k perbulan udh sama Disney '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-20 15:25:44+00:00</td>\n",
       "      <td>b'@yunointherain Oke Kak. Gyan cek dulu DM nya...</td>\n",
       "      <td>Oke Kak Gyan cek dulu DM nya ya Makasih Gyan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-20 15:25:43+00:00</td>\n",
       "      <td>b'@Telkomsel udah min cek dmnya yaa';;;;</td>\n",
       "      <td>udah min cek dmnya yaa'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-20 15:23:59+00:00</td>\n",
       "      <td>b'@iskameraa Oke Kak. Gyan cek dulu DM nya ya....</td>\n",
       "      <td>Oke Kak Gyan cek dulu DM nya ya Makasih Gyan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-20 15:23:58+00:00</td>\n",
       "      <td>b'@Telkomsel sudah ada di dm kakak :)';;;;</td>\n",
       "      <td>sudah ada di dm kakak '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-04-20 15:23:33+00:00</td>\n",
       "      <td>b'TELKOMSEL MAHAL BGT ANJIR KUOTANYA NANGISSSS...</td>\n",
       "      <td>TELKOMSEL MAHAL BGT ANJIR KUOTANYA NANGISSSSSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-20 15:23:33+00:00</td>\n",
       "      <td>b'Pensiunan Dosen di Purwokerto Menangkan Toyo...</td>\n",
       "      <td>Pensiunan Dosen di Purwokerto Menangkan Toyot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-04-20 15:23:11+00:00</td>\n",
       "      <td>b'@koacikriyuk Waduh Maafin ya Kak. Sulis lagi...</td>\n",
       "      <td>Waduh Maafin ya Kak Sulis lagi memastikan ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-04-20 15:21:55+00:00</td>\n",
       "      <td>b'@summerbrxxze Halo kak Elfu Terimakasih atas...</td>\n",
       "      <td>Halo kak Elfu Terimakasih atas apresiasinya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-04-20 15:21:32+00:00</td>\n",
       "      <td>b'Barusan nyuruh DM...  \\nTp di PHP in \\xf0\\x9...</td>\n",
       "      <td>Barusan nyuruh DM nTp di PHP in xf xf x x xf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tanggal  \\\n",
       "0  2022-04-20 15:27:28+00:00   \n",
       "1  2022-04-20 15:25:44+00:00   \n",
       "2  2022-04-20 15:25:43+00:00   \n",
       "3  2022-04-20 15:23:59+00:00   \n",
       "4  2022-04-20 15:23:58+00:00   \n",
       "5  2022-04-20 15:23:33+00:00   \n",
       "6  2022-04-20 15:23:33+00:00   \n",
       "7  2022-04-20 15:23:11+00:00   \n",
       "8  2022-04-20 15:21:55+00:00   \n",
       "9  2022-04-20 15:21:32+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  b'@scorpeeoss aku pk Telkomsel 25-29k perbulan...   \n",
       "1  b'@yunointherain Oke Kak. Gyan cek dulu DM nya...   \n",
       "2           b'@Telkomsel udah min cek dmnya yaa';;;;   \n",
       "3  b'@iskameraa Oke Kak. Gyan cek dulu DM nya ya....   \n",
       "4         b'@Telkomsel sudah ada di dm kakak :)';;;;   \n",
       "5  b'TELKOMSEL MAHAL BGT ANJIR KUOTANYA NANGISSSS...   \n",
       "6  b'Pensiunan Dosen di Purwokerto Menangkan Toyo...   \n",
       "7  b'@koacikriyuk Waduh Maafin ya Kak. Sulis lagi...   \n",
       "8  b'@summerbrxxze Halo kak Elfu Terimakasih atas...   \n",
       "9  b'Barusan nyuruh DM...  \\nTp di PHP in \\xf0\\x9...   \n",
       "\n",
       "                                                text  \n",
       "0     aku pk Telkomsel  k perbulan udh sama Disney '  \n",
       "1      Oke Kak Gyan cek dulu DM nya ya Makasih Gyan'  \n",
       "2                            udah min cek dmnya yaa'  \n",
       "3      Oke Kak Gyan cek dulu DM nya ya Makasih Gyan'  \n",
       "4                            sudah ada di dm kakak '  \n",
       "5     TELKOMSEL MAHAL BGT ANJIR KUOTANYA NANGISSSSSA  \n",
       "6   Pensiunan Dosen di Purwokerto Menangkan Toyot...  \n",
       "7    Waduh Maafin ya Kak Sulis lagi memastikan ga...  \n",
       "8    Halo kak Elfu Terimakasih atas apresiasinya ...  \n",
       "9   Barusan nyuruh DM nTp di PHP in xf xf x x xf ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = cleaned\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "data['text'] = data['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(text):\n",
    "    return word_tokenize(text)\n",
    "data['text'] = data['text'].apply(tokenizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [aku, pk, telkomsel, perbulan, udh, sama, disney]\n",
      "1     [oke, kak, gyan, cek, dulu, dm, nya, ya, makas...\n",
      "2                          [udah, min, cek, dmnya, yaa]\n",
      "3     [oke, kak, gyan, cek, dulu, dm, nya, ya, makas...\n",
      "4                           [sudah, ada, di, dm, kakak]\n",
      "                            ...                        \n",
      "95    [halo, kak, ada, yg, bisa, sulis, bantu, sulis...\n",
      "96                  [telkomsel, bapuk, bgt, sih, tolol]\n",
      "97    [coba, lgsg, dtg, ke, gerai, telkomsel, aja, k...\n",
      "98    [hendrazm, oke, kak, gyan, cek, dulu, dm, nya,...\n",
      "99                               [min, tolong, cek, dm]\n",
      "Name: text, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "list_stopwords = ([\"b\", \"xef\", \"x\", \"xa\",\"n\", \"xe\", \"xf\",\"xb\", \"xad\", \"xd\",\"xxxxxxx\",\n",
    "                  \"xba\", \"xc\", \"k\", \"xcche\", \"xd xd xaa xd xd xd xd\", \"m\", \"t\", \"xbb\", \"f\",\n",
    "                  \"xbf\",\"xbd\",\"xbc\",\"xab\"])\n",
    "\n",
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "data['text'] = data['text'].apply(stopwords_removal)\n",
    "\n",
    "\n",
    "print(data['text'].head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         aku pakai telkomsel perbulan udah sama disney\n",
       "1          oke kak gyan cek dulu dm nya ya makasih gyan\n",
       "2                               sudah min cek dmnya yaa\n",
       "3          oke kak gyan cek dulu dm nya ya makasih gyan\n",
       "4                                 sudah ada di dm kakak\n",
       "                            ...                        \n",
       "95    halo kak ada yang bisa sulis bantu sulis siap ...\n",
       "96                     telkomsel bapuk banget sih tolol\n",
       "97    coba langsung datang ke gerai telkomsel saja k...\n",
       "98    hendrazm oke kak gyan cek dulu dm nya ya makas...\n",
       "99                                    min tolong cek dm\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizad_word = pd.read_excel(\"normalisasi.xlsx\")\n",
    "\n",
    "normalizad_word_dict = {}\n",
    "\n",
    "for index, row in normalizad_word.iterrows():\n",
    "    if row[0] not in normalizad_word_dict:\n",
    "        normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "data['text'] = data['text'].apply(normalized_term).str.join(\" \")\n",
    "data['text'].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "------------------------\n",
      "a : a\n",
      "k : k\n",
      "u : u\n",
      "  : \n",
      "p : p\n",
      "i : i\n",
      "t : t\n",
      "e : e\n",
      "l : l\n",
      "o : o\n",
      "m : m\n",
      "s : s\n",
      "r : r\n",
      "b : b\n",
      "n : n\n",
      "d : d\n",
      "h : h\n",
      "y : y\n",
      "g : g\n",
      "c : c\n",
      "j : j\n",
      "w : w\n",
      "z : z\n",
      "f : f\n",
      "v : v\n",
      "x : x\n",
      "q : q\n",
      "{'a': 'a', 'k': 'k', 'u': 'u', ' ': '', 'p': 'p', 'i': 'i', 't': 't', 'e': 'e', 'l': 'l', 'o': 'o', 'm': 'm', 's': 's', 'r': 'r', 'b': 'b', 'n': 'n', 'd': 'd', 'h': 'h', 'y': 'y', 'g': 'g', 'c': 'c', 'j': 'j', 'w': 'w', 'z': 'z', 'f': 'f', 'v': 'v', 'x': 'x', 'q': 'q'}\n",
      "------------------------\n",
      "0        [a, k, u, , p, a, k, a, i, , t, e, l, k, o, m,...\n",
      "1        [o, k, e, , k, a, k, , g, y, a, n, , c, e, k, ...\n",
      "2        [s, u, d, a, h, , m, i, n, , c, e, k, , d, m, ...\n",
      "3        [o, k, e, , k, a, k, , g, y, a, n, , c, e, k, ...\n",
      "4        [s, u, d, a, h, , a, d, a, , d, i, , d, m, , k...\n",
      "                               ...                        \n",
      "25045    [h, a, i, , k, a, k, , d, e, l, v, i, y, , p, ...\n",
      "25046    [t, e, l, k, o, m, s, e, l, , m, e, m, a, n, g...\n",
      "25047    [a, p, a, k, a, h, , k, a, r, t, u, , h, a, l,...\n",
      "25048    [t, e, l, k, o, m, s, e, l, , t, l, o, n, g, ,...\n",
      "25049    [s, i, a, p, , k, a, k, , j, a, n, g, a, n, , ...\n",
      "Name: text, Length: 24762, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemmed_wrapper(term):\n",
    "    return stemmer.stem(term)\n",
    "\n",
    "term_dict = {}\n",
    "\n",
    "for document in data['text']:\n",
    "    for term in document:\n",
    "        if term not in term_dict:\n",
    "            term_dict[term] = ' '\n",
    "            \n",
    "print(len(term_dict))\n",
    "print(\"------------------------\")\n",
    "\n",
    "for term in term_dict:\n",
    "    term_dict[term] = stemmed_wrapper(term)\n",
    "    print(term,\":\" ,term_dict[term])\n",
    "    \n",
    "print(term_dict)\n",
    "print(\"------------------------\")\n",
    "\n",
    "def get_stemmed_term(document):\n",
    "    return [term_dict[term] for term in document]\n",
    "\n",
    "tweet_stemmer = data['text'].apply(get_stemmed_term)\n",
    "print(tweet_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(data)\n",
    "data.to_excel(\"hasil_preprocessing.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pelabelan Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kelas</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>mahal banget anjir kuota menang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>nyuruh dm ntp di php in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>kenapa sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>kuota masih ada gb kenapa lot yh ini handphone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>plis kalau buat paket data tidak usah aneh ane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>mahal kira bakal makin baik ehhhhhhh sinyal bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>di bantu dari siang nomor saya tidak ada jarin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>tolong dong ini sudah hampir bulan begini kok ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>salah sms pakai nomor telkomsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>kami tidak maksud ngempar lempar kok kak kami ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kelas  label                                              tweet\n",
       "0  Negatif     -1                    mahal banget anjir kuota menang\n",
       "1  Negatif     -1                            nyuruh dm ntp di php in\n",
       "2  Negatif     -1                                         kenapa sih\n",
       "3  Negatif     -1  kuota masih ada gb kenapa lot yh ini handphone...\n",
       "4  Negatif     -1  plis kalau buat paket data tidak usah aneh ane...\n",
       "5  Negatif     -1  mahal kira bakal makin baik ehhhhhhh sinyal bu...\n",
       "6  Negatif     -1  di bantu dari siang nomor saya tidak ada jarin...\n",
       "7  Negatif     -1  tolong dong ini sudah hampir bulan begini kok ...\n",
       "8  Negatif     -1                    salah sms pakai nomor telkomsel\n",
       "9  Negatif     -1  kami tidak maksud ngempar lempar kok kak kami ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet = pd.read_excel(\"data_training.xlsx\")\n",
    "data_tweet = data_tweet[['kelas','label','tweet']].fillna(' ')\n",
    "data_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    200\n",
       " 1    200\n",
       " 0    200\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kelas</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>mahal banget anjir kuota menang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>nyuruh dm ntp di php in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>kenapa sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>kuota masih ada gb kenapa lot yh ini handphone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>plis kalau buat paket data tidak usah aneh ane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>mahal kira bakal makin baik ehhhhhhh sinyal bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>di bantu dari siang nomor saya tidak ada jarin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>tolong dong ini sudah hampir bulan begini kok ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>salah sms pakai nomor telkomsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "      <td>kami tidak maksud ngempar lempar kok kak kami ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kelas  label                                              tweet\n",
       "0  Negatif     -1                    mahal banget anjir kuota menang\n",
       "1  Negatif     -1                            nyuruh dm ntp di php in\n",
       "2  Negatif     -1                                         kenapa sih\n",
       "3  Negatif     -1  kuota masih ada gb kenapa lot yh ini handphone...\n",
       "4  Negatif     -1  plis kalau buat paket data tidak usah aneh ane...\n",
       "5  Negatif     -1  mahal kira bakal makin baik ehhhhhhh sinyal bu...\n",
       "6  Negatif     -1  di bantu dari siang nomor saya tidak ada jarin...\n",
       "7  Negatif     -1  tolong dong ini sudah hampir bulan begini kok ...\n",
       "8  Negatif     -1                    salah sms pakai nomor telkomsel\n",
       "9  Negatif     -1  kami tidak maksud ngempar lempar kok kak kami ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet = pd.read_excel(\"data_training.xlsx\")\n",
    "data_tweet = data_tweet[['kelas','label','tweet']].fillna(' ')\n",
    "data_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tweet_import():\n",
    "    data_tweet.columns = ['kelas','label','tweet']\n",
    "    data_tweet.sentiment = data_tweet.sentiment.replace(4,1)\n",
    "    return data_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data, method = \"tfidf\"):\n",
    "    tfv=TfidfVectorizer(sublinear_tf=True) \n",
    "    features=tfv.fit_transform(data)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(features, Label, classifier = \"naive_bayes\"):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data_tweet.tweet)\n",
    "label = np.array(data_tweet.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 867)\t0.4196849411638045\n",
      "  (0, 123)\t0.30766527808464766\n",
      "  (0, 63)\t0.5715530253799128\n",
      "  (0, 780)\t0.37919645761811666\n",
      "  (0, 915)\t0.5086686667471969\n",
      "  (1, 1104)\t0.48205560149585386\n",
      "  (1, 369)\t0.20575909336598291\n",
      "  (1, 1080)\t0.5130805641920425\n",
      "  (1, 339)\t0.23575696717894326\n",
      "  (1, 1174)\t0.48205560149585386\n",
      "  (1, 573)\t0.41722293405937283\n",
      "  (2, 712)\t0.6510898943682388\n",
      "  (2, 1368)\t0.7590006254619002\n",
      "  (3, 780)\t0.2419938209990717\n",
      "  (3, 712)\t0.21624777964852251\n",
      "  (3, 900)\t0.2578829320067233\n",
      "  (3, 7)\t0.20071605958572092\n",
      "  (3, 468)\t0.28448854385315003\n",
      "  (3, 845)\t0.4665698321998816\n",
      "  (3, 1625)\t0.3882263092132509\n",
      "  (3, 585)\t0.1974067503703279\n",
      "  (3, 528)\t0.19959180777124377\n",
      "  (3, 1623)\t0.179164455995946\n",
      "  (3, 69)\t0.34809506346745767\n",
      "  (3, 626)\t0.22591973491643588\n",
      "  :\t:\n",
      "  (596, 153)\t0.20289202948100024\n",
      "  (596, 1206)\t0.2568294378491072\n",
      "  (596, 498)\t0.2568294378491072\n",
      "  (596, 654)\t0.502421798505138\n",
      "  (596, 1219)\t0.29673840778506966\n",
      "  (596, 251)\t0.29673840778506966\n",
      "  (596, 996)\t0.29673840778506966\n",
      "  (596, 706)\t0.29673840778506966\n",
      "  (597, 468)\t0.34102028792197076\n",
      "  (597, 222)\t0.28221603670362566\n",
      "  (597, 1460)\t0.15503103387228168\n",
      "  (597, 1231)\t0.3609860280121651\n",
      "  (597, 892)\t0.46537215858901776\n",
      "  (597, 384)\t0.46537215858901776\n",
      "  (597, 1393)\t0.46537215858901776\n",
      "  (598, 1460)\t0.27204581182713006\n",
      "  (598, 1133)\t0.5090296880568337\n",
      "  (598, 873)\t0.8166271198925985\n",
      "  (599, 123)\t0.20428539648507316\n",
      "  (599, 1416)\t0.17735782154246346\n",
      "  (599, 1360)\t0.2959944804201647\n",
      "  (599, 90)\t0.3377488058220045\n",
      "  (599, 1136)\t0.3069773045932285\n",
      "  (599, 1011)\t0.6839092933113484\n",
      "  (599, 1188)\t0.4039278458268294\n"
     ]
    }
   ],
   "source": [
    "features = feature_extraction(data, method = \"tfidf\") \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>kelas</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mahal banget anjir kuota menang</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nyuruh dm ntp di php in</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kenapa sih</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kuota masih ada gb kenapa lot yh ini handphone...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plis kalau buat paket data tidak usah aneh ane...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mahal kira bakal makin baik ehhhhhhh sinyal bu...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>di bantu dari siang nomor saya tidak ada jarin...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tolong dong ini sudah hampir bulan begini kok ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>salah sms pakai nomor telkomsel</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kami tidak maksud ngempar lempar kok kak kami ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet    kelas  label\n",
       "0                    mahal banget anjir kuota menang  Negatif     -1\n",
       "1                            nyuruh dm ntp di php in  Negatif     -1\n",
       "2                                         kenapa sih  Negatif     -1\n",
       "3  kuota masih ada gb kenapa lot yh ini handphone...  Negatif     -1\n",
       "4  plis kalau buat paket data tidak usah aneh ane...  Negatif     -1\n",
       "5  mahal kira bakal makin baik ehhhhhhh sinyal bu...  Negatif     -1\n",
       "6  di bantu dari siang nomor saya tidak ada jarin...  Negatif     -1\n",
       "7  tolong dong ini sudah hampir bulan begini kok ...  Negatif     -1\n",
       "8                    salah sms pakai nomor telkomsel  Negatif     -1\n",
       "9  kami tidak maksud ngempar lempar kok kak kami ...  Negatif     -1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet = pd.read_excel(\"data_training.xlsx\")\n",
    "data_tweet = data_tweet[['tweet','kelas', 'label']].fillna(' ')\n",
    "data_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_tweet['tweet']\n",
    "y = data_tweet['label']\n",
    "\n",
    "bow_transformer = CountVectorizer().fit(data_tweet['tweet'])\n",
    "messages_bow = bow_transformer.transform(data_tweet['tweet'])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data_tweet['tweet'],data_tweet['label'],test_size=0.1,random_state=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "    ])\n",
    "\n",
    "X_train = np.asarray(X)\n",
    "pipeline = pipeline.fit(X_train, np.asarray(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = 'latihan_ta.pickle'\n",
    "f = open(file_data, 'wb')\n",
    "pickle.dump(pipeline, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('bow',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('tfidf',\n",
      "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
      "                                  sublinear_tf=False, use_idf=True)),\n",
      "                ('classifier',\n",
      "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "file_dataset = 'latihan_ta.pickle'\n",
    "f = open(file_dataset, 'rb')\n",
    "training = pickle.load(f)\n",
    "f.close()\n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweet = pd.read_excel('testing.xlsx')\n",
    "data_tweet = data_tweet['tweet'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = training.predict(np.asarray(data_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if(prediction[i]==1):\n",
    "        sentiment = 'Positif'\n",
    "    elif(prediction[i]==0):\n",
    "        sentiment = 'Netral'\n",
    "    else:\n",
    "        sentiment = 'Negatif'\n",
    "    \n",
    "    result.append({'tweet':data_tweet[i],'label':prediction[i],'kelas':sentiment})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>kelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zii jia amp axelsen sudah kayak telkomsel jang...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuk tonton kolak express the series di maxstre...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yuk cv pulsa di kak indosat isat rate telkomse...</td>\n",
       "      <td>0</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yang paling lambat di muka bumi adalah jaring</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yang pake telkomsel sinyal bagus tidak</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>colek nsinyal internet bosok tur lot e</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>biasa bisa kasih nyaman</td>\n",
       "      <td>1</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>anjir baru nyadar hahahaa nbtw aku juga telko...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>anda bapuk mending juga telkomsel mana</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>ada yang mau trf wifi jan sampe mati okey</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  label    kelas\n",
       "0    zii jia amp axelsen sudah kayak telkomsel jang...      1  Positif\n",
       "1    yuk tonton kolak express the series di maxstre...      1  Positif\n",
       "2    yuk cv pulsa di kak indosat isat rate telkomse...      0   Netral\n",
       "3        yang paling lambat di muka bumi adalah jaring     -1  Negatif\n",
       "4               yang pake telkomsel sinyal bagus tidak     -1  Negatif\n",
       "..                                                 ...    ...      ...\n",
       "331             colek nsinyal internet bosok tur lot e     -1  Negatif\n",
       "332                            biasa bisa kasih nyaman      1  Positif\n",
       "333   anjir baru nyadar hahahaa nbtw aku juga telko...     -1  Negatif\n",
       "334             anda bapuk mending juga telkomsel mana     -1  Negatif\n",
       "335          ada yang mau trf wifi jan sampe mati okey     -1  Negatif\n",
       "\n",
       "[336 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet = pd.DataFrame(result)\n",
    "data_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [6,5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "x = ['Positif', 'Netral', 'Negatif',]\n",
    "y = [1726,2673, 263]\n",
    "percentage = [1726,2673, 263]\n",
    "ax = sns.barplot(x=x, y=y)\n",
    "patches = ax.patches\n",
    "for i in range(len(patches)):\n",
    "    x = patches[i].get_x() + patches[i].get_width()/2\n",
    "    y = patches[i].get_height()+.5\n",
    "    ax.annotate('{:}'.format(percentage[i]), (x, y), ha='center')\n",
    "    \n",
    "plt.title('Klasifikasi Sentimen \\n')\n",
    "plt.xlabel('Jenis Klasifikasi')\n",
    "plt.ylabel('Jumlah')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
